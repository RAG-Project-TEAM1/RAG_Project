import re
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

@dataclass
class LineInfo:
    """ë¼ì¸ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    original: str
    type: str
    level: int
    content: str
    line_index: int
    is_consecutive: bool = False
    should_remove: bool = False

class OptimizedMarkdownConverter:
    """
    Markdown ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì˜ë¯¸ ìˆëŠ” ì œëª© í—¤ë”ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    ëª©ì°¨(TOC) ê°ì§€ ë° ì œê±° ê¸°ëŠ¥
    
    ì£¼ìš” ê¸°ëŠ¥:
        - ë¡œë§ˆ ìˆ«ì, ê³„ì¸µí˜• ìˆ«ì(1.1, 1.2.3 ë“±) ê¸°ë°˜ì˜ ì„¹ì…˜ ì¸ì‹
        - ëª©ì°¨ ì„¹ì…˜ ìë™ ê°ì§€ ë° ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ìœ ì§€
        - ì  ì—†ëŠ” ìˆ«ì íŒ¨í„´ (1 ì¶”ì§„ëª©í‘œ) ì§€ì›
        - ì‹¬ë³¼(â–¡, â—‹, â€¢ ë“±)ì€ í—¤ë”ë¡œ ë³€í™˜í•˜ì§€ ì•ŠìŒ
        - # (H1)ê³¼ ## (H2) ë ˆë²¨ë¡œë§Œ êµ¬ì„±
    """    
    def __init__(self):
        self.max_header_length = 60 
        self.min_header_length = 2
        self.enable_consecutive_header_removal = True
        
        # ì •ê·œì‹ íŒ¨í„´ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬
        self.patterns = self._compile_patterns()
        
        # ë¡œë§ˆ ìˆ«ì ì¶”ì ì„ ë‹¨ìˆœí™”
        self.has_roman_numerals = False
        
    def _compile_patterns(self) -> Dict[str, Dict[str, re.Pattern]]:
        """íŒ¨í„´ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬í•˜ì—¬ ì»´íŒŒì¼"""
        return {
            'roman': {
                'unicode': re.compile(r'^(â… |â…¡|â…¢|â…£|â…¤|â…¥|â…¦|â…§|â…¨|â…©)\.?\s*(.+)'),
                'ascii': re.compile(r'^([IVX]+)\.?\s*(.+)', re.IGNORECASE)
            },
            'numbered': {
                'hierarchical': re.compile(r'^(\d+(?:\.\d+)*)\.\s*(.+)'),
                'simple': re.compile(r'^(\d+)\s+(.+)')  # ì  ì—†ëŠ” ìˆ«ì íŒ¨í„´ ì¶”ê°€
            },
            'symbols': {
                'square': re.compile(r'^â–¡\s*(.+)'),
                'note': re.compile(r'^â€»\s*(.+)'),
                'circle': re.compile(r'^â—‹\s*(.+)'),
                'bullet': re.compile(r'^â€¢\s*(.+)'),
                'dash': re.compile(r'^-\s*(.+)')
            },
            'exclude': {
                'parentheses': re.compile(r'^\d+\)\s*(.+)'),
                'korean_paren': re.compile(r'^[ê°€-í£]\)\s*(.+)'),
                'alpha_paren': re.compile(r'^[a-zA-Z]\)\s*(.+)')
            },
            'cleanup': {
                'markdown_header': re.compile(r'^#+\s*(.*)'),
                'meaningless': re.compile(r'^[#\s]*$|^[#\sÂ·â€¢\-_=]*$|^[#\s]*\.\s*$')
            },
            'toc': {
                # ëª©ì°¨ íŒ¨í„´: ë¡œë§ˆìˆ«ì + í…ìŠ¤íŠ¸ + ì ì„  + í˜ì´ì§€ë²ˆí˜¸
                'roman_toc': re.compile(r'^(â… |â…¡|â…¢|â…£|â…¤|â…¥|â…¦|â…§|â…¨|â…©)\.?\s*(.+?)[\sÂ·]{2,}\s*\d+$'),
                # ìˆ«ì ëª©ì°¨: 1. ì œëª© Â·Â·Â· í˜ì´ì§€
                'numbered_toc': re.compile(r'^(\d+(?:\.\d+)*)\.\s*(.+?)[\sÂ·]{2,}\s*\d+$'),
                # ì¼ë°˜ ëª©ì°¨: í…ìŠ¤íŠ¸ Â·Â·Â· í˜ì´ì§€
                'general_toc': re.compile(r'^(.+?)[\sÂ·]{3,}\s*\d+$'),
                # ì ì„ ë§Œ ìˆëŠ” ë¼ì¸
                'dotted_line': re.compile(r'^[Â·\s]{3,}$')
            }
        }

    def _is_toc_line(self, line: str) -> bool:
        """ëª©ì°¨ ë¼ì¸ì¸ì§€ íŒë‹¨"""
        line = line.strip()
        
        # ë¹ˆ ë¼ì¸ì´ê±°ë‚˜ ì ì„ ë§Œ ìˆëŠ” ë¼ì¸
        if not line or self.patterns['toc']['dotted_line'].match(line):
            return True
            
        # ë¡œë§ˆìˆ«ì ëª©ì°¨ íŒ¨í„´
        if self.patterns['toc']['roman_toc'].match(line):
            return True
            
        # ìˆ«ì ëª©ì°¨ íŒ¨í„´
        if self.patterns['toc']['numbered_toc'].match(line):
            return True
            
        # ì¼ë°˜ ëª©ì°¨ íŒ¨í„´ (ì œëª©Â·Â·í˜ì´ì§€)
        if self.patterns['toc']['general_toc'].match(line):
            return True
            
        return False

    def _detect_toc_section(self, lines: List[str]) -> Tuple[int, int]:
        """
        ëª©ì°¨ ì„¹ì…˜ì˜ ì‹œì‘ê³¼ ëì„ ê°ì§€
        Returns: (start_index, end_index) - ëª©ì°¨ê°€ ì—†ìœ¼ë©´ (-1, -1)
        """
        toc_start = -1
        toc_end = -1
        consecutive_toc_count = 0
        
        for i, line in enumerate(lines):
            if self._is_toc_line(line):
                if toc_start == -1:
                    toc_start = i
                consecutive_toc_count += 1
                toc_end = i
            else:
                # ëª©ì°¨ê°€ ì•„ë‹Œ ë¼ì¸ì´ ë‚˜ì™”ì„ ë•Œ
                if consecutive_toc_count >= 3:  # ìµœì†Œ 3ì¤„ ì´ìƒì˜ ëª©ì°¨ íŒ¨í„´ì´ ìˆì–´ì•¼ ëª©ì°¨ë¡œ ì¸ì •
                    break
                else:
                    # ëª©ì°¨ íŒ¨í„´ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ë¦¬ì…‹
                    toc_start = -1
                    toc_end = -1
                    consecutive_toc_count = 0
        
        # ëª©ì°¨ íŒ¨í„´ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ëª©ì°¨ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
        if consecutive_toc_count < 3:
            return -1, -1
            
        return toc_start, toc_end

    def _is_valid_text(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ìœ íš¨í•œ í—¤ë” í…ìŠ¤íŠ¸ì¸ì§€ í†µí•© ê²€ì¦"""
        if not text or len(text.strip()) < self.min_header_length:
            return False
        
        clean_text = text.strip()
        if len(clean_text) > self.max_header_length:
            return False
        
        # ì˜ë¯¸ì—†ëŠ” íŒ¨í„´ë“¤ì„ í†µí•©
        meaningless_patterns = [
            r'^[Â·â€¢\-_=]{1,5}$',
            r'^\d+\.?$',
            r'^\[.*\].*Â·Â·Â·\s*\d+$',
            r'^<.*>$',
            r'^ã…‡\s',
            r'.*\(\d{4}\.\d{1,2}\.\d{1,2}\.?ê¸°ì¤€\)',
            r'.*Â·Â·Â·\s*\d+$',
            r'.*[\sÂ·]{3,}\s*\d+$'  # ëª©ì°¨ íŒ¨í„´ ì¶”ê°€
        ]
        
        return not any(re.match(pattern, clean_text) for pattern in meaningless_patterns)

    def _extract_roman_numeral(self, line: str) -> Optional[Tuple[str, str]]:
        """ë¡œë§ˆ ìˆ«ì ì¶”ì¶œ í†µí•© ë©”ì„œë“œ (ëª©ì°¨ ì œì™¸)"""
        # ëª©ì°¨ íŒ¨í„´ì¸ì§€ ë¨¼ì € í™•ì¸
        if self._is_toc_line(line):
            return None
            
        # ìœ ë‹ˆì½”ë“œ ë¡œë§ˆ ìˆ«ì ë¨¼ì € í™•ì¸
        match = self.patterns['roman']['unicode'].match(line)
        if match:
            return match.group(1), match.group(2).strip()
        
        # ASCII ë¡œë§ˆ ìˆ«ì í™•ì¸
        match = self.patterns['roman']['ascii'].match(line)
        if match and self._is_valid_roman_numeral(match.group(1)):
            return match.group(1), match.group(2).strip()
        
        return None

    def _is_valid_roman_numeral(self, text: str) -> bool:
        """ë¡œë§ˆ ìˆ«ì ìœ íš¨ì„± ê²€ì‚¬"""
        valid_romans = {
            'I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X',
            'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI', 'XVII', 'XVIII', 'XIX', 'XX'
        }
        return text.upper() in valid_romans

    def _classify_line_type(self, line: str, line_index: int, in_toc_section: bool = False) -> LineInfo:
        """ë¼ì¸ ë¶„ë¥˜ ë¡œì§ì„ ë‹¨ìˆœí™” (ëª©ì°¨ ì²˜ë¦¬ ì¶”ê°€)"""
        line = line.strip()
        
        if not line:
            return LineInfo('', 'empty', 0, '', line_index)
        
        # ëª©ì°¨ ì„¹ì…˜ ë‚´ì˜ ë¼ì¸ì€ ëª¨ë‘ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
        if in_toc_section:
            return LineInfo(line, 'toc_content', 0, line, line_index)
        
        # ì œì™¸ íŒ¨í„´ ë¨¼ì € í™•ì¸
        for pattern in self.patterns['exclude'].values():
            if pattern.match(line):
                return LineInfo(line, 'excluded', 0, line, line_index)
        
        # ë¡œë§ˆ ìˆ«ì í™•ì¸
        roman_result = self._extract_roman_numeral(line)
        if roman_result:
            roman_num, header_text = roman_result
            if self._is_valid_text(header_text):
                self.has_roman_numerals = True
                return LineInfo(line, 'roman', 1, line, line_index)  # ì›ë³¸ line ìœ ì§€
        
        # ê³„ì¸µí˜• ìˆ«ì í™•ì¸ (ì  ìˆëŠ” ë²„ì „)
        match = self.patterns['numbered']['hierarchical'].match(line)
        if match:
            number_part, header_text = match.groups()
            if self._is_valid_text(header_text):
                # ë¡œë§ˆ ìˆ«ìê°€ ìˆìœ¼ë©´: 1.xëŠ” H2, ë¡œë§ˆ ìˆ«ìê°€ ì—†ìœ¼ë©´: 1ì€ H1, 1.xëŠ” H2
                if self.has_roman_numerals:
                    level = 2  # ë¡œë§ˆ ìˆ«ì ë‹¤ìŒì€ ëª¨ë‘ H2
                else:
                    level = 1 if number_part.count('.') == 0 else 2
                return LineInfo(line, 'numbered', level, line, line_index)  # ì›ë³¸ line ìœ ì§€
        
        # ì  ì—†ëŠ” ìˆ«ì íŒ¨í„´ (1 ì¶”ì§„ëª©í‘œ)
        match = self.patterns['numbered']['simple'].match(line)
        if match:
            number_part, header_text = match.groups()
            if self._is_valid_text(header_text):
                # ë¡œë§ˆ ìˆ«ìê°€ ìˆìœ¼ë©´ H2, ì—†ìœ¼ë©´ H1
                level = 2 if self.has_roman_numerals else 1
                return LineInfo(line, 'numbered_simple', level, line, line_index)  # ì›ë³¸ line ìœ ì§€
        
        # ì‹¬ë³¼ íŒ¨í„´ë“¤ì€ í—¤ë”ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ (ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ìœ ì§€)
        # for symbol_type, pattern in self.patterns['symbols'].items():
        #     match = pattern.match(line)
        #     if match and self._is_valid_text(match.group(1)):
        #         return LineInfo(line, symbol_type, 2, line, line_index)
        
        # ì œëª© í˜•íƒœ í™•ì¸ (ë¡œë§ˆ ìˆ«ìê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
        if not self.has_roman_numerals and self._looks_like_title(line):
            return LineInfo(line, 'title', 1, line, line_index)  # ì›ë³¸ line ìœ ì§€
        
        return LineInfo(line, 'text', 0, line, line_index)

    def _looks_like_title(self, line: str) -> bool:
        """ì œëª© íŒë³„ ë¡œì§ ë‹¨ìˆœí™”"""
        if len(line) > 50:
            return False
        
        # ì œëª© í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ
        title_keywords = ['ëª©ì ', 'ê°œìš”', 'ìš”ì•½', 'ê²°ë¡ ', 'ë°°ê²½']
        return any(keyword in line for keyword in title_keywords)

    def _mark_consecutive_headers(self, lines: List[LineInfo]) -> List[LineInfo]:
        """ì—°ì†ë˜ëŠ” í—¤ë” ë¼ì¸ì„ ì œê±°í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜"""
        if not self.enable_consecutive_header_removal:
            return lines
        
        result = []
        consecutive_count = 0
        
        for i, line_info in enumerate(lines):
            is_header = line_info.level > 0
            next_is_header = (i + 1 < len(lines) and lines[i + 1].level > 0)
            
            if is_header:
                consecutive_count += 1
                
                # ì œê±° ì¡°ê±´ë“¤ì„ ëª…í™•íˆ ë¶„ë¦¬
                should_remove = (
                    consecutive_count >= 2 or
                    line_info.content.strip().endswith(':') or 
                    next_is_header  
                )
                
                if should_remove:
                    # í—¤ë”ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    clean_content = re.sub(r'^#+\s*', '', line_info.content).strip()
                    line_info = LineInfo(
                        original=clean_content,
                        type='converted_text',
                        level=0,
                        content=clean_content,
                        line_index=line_info.line_index,
                        should_remove=True
                    )
                    consecutive_count = 0 
            else:
                consecutive_count = 0
            
            result.append(line_info)
        
        return result

    def convert_document(self, text: str) -> str:
        """ë©”ì¸ ë³€í™˜ ë¡œì§ (ëª©ì°¨ ì²˜ë¦¬ ì¶”ê°€)"""
        # ê¸°ì¡´ í—¤ë” ì •ë¦¬
        cleaned_text = self._clean_existing_headers(text)
        lines = cleaned_text.split('\n')
        
        # ëª©ì°¨ ì„¹ì…˜ ê°ì§€
        toc_start, toc_end = self._detect_toc_section(lines)
        
        if toc_start != -1:
            print(f"ëª©ì°¨ ì„¹ì…˜ ê°ì§€ë¨: {toc_start+1}ì¤„ ~ {toc_end+1}ì¤„ (ì´ {toc_end-toc_start+1}ì¤„)")
        
        self.has_roman_numerals = False
        
        # ë¼ì¸ë³„ ë¶„ë¥˜ (ëª©ì°¨ ì„¹ì…˜ ì •ë³´ ì „ë‹¬)
        analyzed_lines = []
        for i, line in enumerate(lines):
            in_toc = toc_start <= i <= toc_end if toc_start != -1 else False
            line_info = self._classify_line_type(line, i, in_toc)
            analyzed_lines.append(line_info)
        
        # ì—°ì† í—¤ë” ì²˜ë¦¬
        processed_lines = self._mark_consecutive_headers(analyzed_lines)
        
        # ë§ˆí¬ë‹¤ìš´ ë³€í™˜
        return self._lines_to_markdown(processed_lines)

    def _clean_existing_headers(self, text: str) -> str:
        """ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ í—¤ë” ì •ë¦¬"""
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            match = self.patterns['cleanup']['markdown_header'].match(line.strip())
            if match:
                cleaned_lines.append(match.group(1).strip())
            else:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)

    def _lines_to_markdown(self, lines: List[LineInfo]) -> str:
        """LineInfo ë¦¬ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
        converted_lines = []
        removed_count = 0
        toc_lines_removed = 0
        
        for line_info in lines:
            if line_info.type == 'toc_content':
                # ëª©ì°¨ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜ ë³„ë„ ì¹´ìš´íŠ¸
                converted_lines.append(line_info.original)
                toc_lines_removed += 1
            elif line_info.level > 0:
                header = '#' * line_info.level
                converted_lines.append(f"{header} {line_info.content}")
            elif line_info.should_remove:
                converted_lines.append(line_info.original)
                removed_count += 1
            else:
                converted_lines.append(line_info.original)
        
        # ì—°ì† ë¹ˆ ì¤„ ì •ë¦¬
        final_lines = self._clean_empty_lines(converted_lines)
        
        if toc_lines_removed > 0:
            print(f"ëª©ì°¨ ì²˜ë¦¬: {toc_lines_removed}ê°œ ë¼ì¸ì„ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ìœ ì§€")
        
        if removed_count > 0:
            print(f"ì—°ì† í—¤ë” ì œê±°: {removed_count}ê°œ í—¤ë”ë¥¼ ë³¸ë¬¸ìœ¼ë¡œ ë³€í™˜")
        
        return '\n'.join(final_lines)

    def _clean_empty_lines(self, lines: List[str]) -> List[str]:
        """ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬"""
        result = []
        prev_empty = False
        
        for line in lines:
            is_empty = line.strip() == ''
            if not (is_empty and prev_empty):
                result.append(line)
            prev_empty = is_empty
        
        return result

    def process_file(self, input_path: str, output_path: Optional[str] = None) -> bool:
        """íŒŒì¼ ì²˜ë¦¬"""
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            converted_content = self.convert_document(content)
            
            if output_path is None:
                input_file = Path(input_path)
                output_path = input_file.parent / f"{input_file.stem}_cleaned.md"
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(converted_content)
            
            print(f"ë³€í™˜ ì™„ë£Œ: {input_path} â†’ {output_path}")
            print(f"   ë¡œë§ˆ ìˆ«ì ì‚¬ìš©: {'ì˜ˆ' if self.has_roman_numerals else 'ì•„ë‹ˆì˜¤'}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def set_consecutive_header_removal_enabled(self, enabled: bool):
        """ì—°ì† í—¤ë” ì œê±° ê¸°ëŠ¥ ì„¤ì •"""
        self.enable_consecutive_header_removal = enabled
        print(f"ğŸ”§ ì—°ì† í—¤ë” ì œê±° ê¸°ëŠ¥: {'í™œì„±í™”' if enabled else 'ë¹„í™œì„±í™”'}")

    def process_directory_recursive(self, root_directory: str):
        """ë””ë ‰í† ë¦¬ ë‚´ë¶€ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ê° íŒŒì¼ì„ ê°œë³„ì ìœ¼ë¡œ _cleaned_2.md ìƒì„±"""
        root_dir = Path(root_directory)
        
        if not root_dir.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {root_directory}")
            return
        
        # ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì˜ .md íŒŒì¼ íƒìƒ‰
        all_md_files = list(root_dir.rglob("*.md"))
        if not all_md_files:
            print(f"âŒ '{root_directory}' ë””ë ‰í† ë¦¬ì—ì„œ .md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ì€ ì œì™¸
        md_files_to_process = []
        for md_file in all_md_files:
            if any(suffix in md_file.stem for suffix in ['_clean', '_cleaned']):
                continue
            md_files_to_process.append(md_file)
        
        if not md_files_to_process:
            print("ì²˜ë¦¬í•  .md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤ (ì´ë¯¸ ë³€í™˜ëœ íŒŒì¼ë“¤ì€ ì œì™¸ë¨)")
            return
        
        print(f"'{root_directory}' ë‚´ ëª¨ë“  .md íŒŒì¼ì„ íƒìƒ‰í•©ë‹ˆë‹¤ (ì´ {len(md_files_to_process)}ê°œ íŒŒì¼ ë°œê²¬)")
        print(f"\nê° íŒŒì¼ì„ ê°œë³„ì ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
        
        successful_files = 0
        
        # ê° íŒŒì¼ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
        for i, md_file in enumerate(md_files_to_process, 1):
            try:
                # íŒŒì¼ì˜ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                try:
                    relative_path = md_file.relative_to(root_dir)
                except ValueError:
                    relative_path = md_file.name
                
                print(f"\n{i}/{len(md_files_to_process)}. {relative_path} ì²˜ë¦¬ ì¤‘...")
                
                # íŒŒì¼ ì½ê¸°
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ê°œë³„ íŒŒì¼ ë³€í™˜
                converted_content = self.convert_document(content)
                
                # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
                original_filename = md_file.stem
                output_filename = f"{original_filename}_cleaned_2.md"
                output_file_path = md_file.parent / output_filename
                
                # ë³€í™˜ëœ ë‚´ìš© ì €ì¥
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    f.write(converted_content)
                
                print(f"   {output_filename} ìƒì„± ì™„ë£Œ (ìœ„ì¹˜: {output_file_path.parent})")
                successful_files += 1
                
            except Exception as e:
                print(f"   íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {md_file.name} â†’ {e}")
                continue
        
        print(f"\nì´ {successful_files}ê°œ íŒŒì¼ì˜ _cleaned_2.md ìƒì„± ì™„ë£Œ!")
        print(f"ëª¨ë“  _cleaned_2.md íŒŒì¼ì€ ì›ë³¸ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ê° íŒŒì¼ì—ì„œ ì˜ë¯¸ì—†ëŠ” í—¤ë”ë“¤ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì—°ì† í—¤ë” ì œê±° ê¸°ëŠ¥ì´ {'ì ìš©' if self.enable_consecutive_header_removal else 'ë¹„í™œì„±í™”'}ë˜ì—ˆìŠµë‹ˆë‹¤.")
