def generate_answer(query, chunks):
    context = ""
    for c in chunks:
        m = c["metadata"]
        context += f"""
ğŸ“„ [ë¬¸ì„œ ì •ë³´]
ì œëª©: {m.get('title', '')}
ì†Œì œëª©: {m.get('subtitle', '')}
ê³µê³ ë²ˆí˜¸: {m.get('ê³µê³  ë²ˆí˜¸', '')}
ë°œì£¼ê¸°ê´€: {m.get('ë°œì£¼ ê¸°ê´€', '')}
ì‚¬ì—…ëª…: {m.get('ì‚¬ì—…ëª…', '')}
ì˜ˆì‚°: {m.get('ì‚¬ì—… ê¸ˆì•¡', '')}
ë§ˆê°ì¼: {m.get('ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼', '')}

ğŸ“‘ [ë³¸ë¬¸]
{c['text']}

""".strip() + "\n\n"

    prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤.

[ì§ˆë¬¸]
{query}

[ë¬¸ì„œ]
{context}

ìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()
ï»¿
