import os
import pandas as pd
import json
from pathlib import Path
import re
import fitz  # PyMuPDF
import olefile
from datetime import datetime
import subprocess
import sys

class ImprovedDocumentConverter:
    def __init__(self, input_dir, output_dir, logs_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.logs_dir = Path(logs_dir)
        self.success_count = 0
        self.failure_count = 0
        self.success_log = []
        self.failure_log = []
        
    def clean_text(self, text, filename):
        """í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ ë¬¸ì¥ë¶€í˜¸ë§Œ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£.,!?;;:()\[\]{}"\'-]', '', text)
        
        # ì—°ì†ëœ ë§ˆì¹¨í‘œ ì œê±°
        text = re.sub(r'\.{2,}', '.', text)
        
        # ë¹ˆ ì¤„ ì œê±°
        text = re.sub(r'\n\s*\n', '\n', text)
        
        return text.strip()
    
    def extract_pdf_text(self, pdf_path):
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        except Exception as e:
            print(f"PDF ì¶”ì¶œ ì˜¤ë¥˜ ({pdf_path}): {e}")
            return ""
    
    def extract_hwp_text_improved(self, hwp_path):
        """HWPì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°œì„ ëœ ë°©ë²•)"""
        try:
            if not olefile.isOleFile(hwp_path):
                return ""
            
            ole = olefile.OleFileIO(hwp_path)
            text = ""
            
            # ëª¨ë“  ìŠ¤íŠ¸ë¦¼ í™•ì¸
            all_streams = ole.listdir()
            print(f"  HWP ìŠ¤íŠ¸ë¦¼ ëª©ë¡: {[stream[0] for stream in all_streams]}")
            
            # ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            streams_to_try = [
                'PrvText',      # ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸
                'Contents',     # ë‚´ìš©
                'BodyText',     # ë³¸ë¬¸ í…ìŠ¤íŠ¸
                'Section0',     # ì„¹ì…˜ 0
                'Section1',     # ì„¹ì…˜ 1
                'DocInfo',      # ë¬¸ì„œ ì •ë³´
                'HwpSummaryInformation',  # ìš”ì•½ ì •ë³´
                'FileHeader',   # íŒŒì¼ í—¤ë”
                'DocOptions',   # ë¬¸ì„œ ì˜µì…˜
            ]
            
            for stream_name in streams_to_try:
                if ole.exists(stream_name):
                    try:
                        stream_content = ole.openstream(stream_name).read()
                        print(f"  ìŠ¤íŠ¸ë¦¼ {stream_name} í¬ê¸°: {len(stream_content)} bytes")
                        
                        # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
                        for encoding in ['utf-8', 'cp949', 'euc-kr', 'utf-16', 'latin1', 'ascii']:
                            try:
                                decoded_text = stream_content.decode(encoding, errors='ignore')
                                if len(decoded_text.strip()) > len(text):
                                    text = decoded_text
                                    print(f"  ì¸ì½”ë”© {encoding}ë¡œ {len(decoded_text)}ì ì¶”ì¶œ")
                            except:
                                continue
                    except Exception as e:
                        print(f"  ìŠ¤íŠ¸ë¦¼ {stream_name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
            
            # ëª¨ë“  ìŠ¤íŠ¸ë¦¼ì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸° ì‹œë„
            if len(text.strip()) < 500:
                for stream_path in all_streams:
                    stream_name = stream_path[0]
                    if stream_name not in streams_to_try:
                        try:
                            stream_content = ole.openstream(stream_name).read()
                            for encoding in ['utf-8', 'cp949', 'euc-kr']:
                                try:
                                    decoded_text = stream_content.decode(encoding, errors='ignore')
                                    if len(decoded_text.strip()) > len(text) and len(decoded_text.strip()) > 100:
                                        text = decoded_text
                                        print(f"  ì¶”ê°€ ìŠ¤íŠ¸ë¦¼ {stream_name}ì—ì„œ {len(decoded_text)}ì ì¶”ì¶œ")
                                except:
                                    continue
                        except:
                            continue
            
            ole.close()
            return text.strip()
            
        except Exception as e:
            print(f"HWP ì¶”ì¶œ ì˜¤ë¥˜ ({hwp_path}): {e}")
            return ""
    
    def find_document_files(self):
        """PDFì™€ HWP íŒŒì¼ ì°¾ê¸°"""
        pdf_files = list(self.input_dir.glob("*.pdf"))
        hwp_files = list(self.input_dir.glob("*.hwp"))
        return pdf_files + hwp_files
    
    def convert_documents(self):
        """ë¬¸ì„œ ë³€í™˜ ì‹¤í–‰"""
        files = self.find_document_files()
        print(f"ğŸ“„ ë³€í™˜í•  íŒŒì¼ ê°œìˆ˜: {len(files)}ê°œ")
        
        for file_path in files:
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            try:
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                if file_path.suffix.lower() == '.pdf':
                    text = self.extract_pdf_text(str(file_path))
                elif file_path.suffix.lower() == '.hwp':
                    # HWP íŒŒì¼ì€ ê°œì„ ëœ ë°©ë²• ì‚¬ìš©
                    text = self.extract_hwp_text_improved(str(file_path))
                else:
                    continue
                
                # í…ìŠ¤íŠ¸ ì •ë¦¬
                cleaned_text = self.clean_text(text, file_path.name)
                
                if cleaned_text and len(cleaned_text) > 100:  # ìµœì†Œ 100ì ì´ìƒ
                    # ê²°ê³¼ ì €ì¥
                    output_file = self.output_dir / f"{file_path.stem}.txt"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(cleaned_text)
                    
                    # ì„±ê³µ ë¡œê·¸
                    self.success_log.append({
                        'filename': file_path.name,
                        'output_file': output_file.name,
                        'text_length': len(cleaned_text),
                        'original_length': len(text),
                        'timestamp': datetime.now().isoformat()
                    })
                    self.success_count += 1
                    print(f"âœ… ì„±ê³µ: {file_path.name} ({len(cleaned_text)}ì)")
                else:
                    raise Exception(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ ({len(cleaned_text)}ì)")
                    
            except Exception as e:
                # ì‹¤íŒ¨ ë¡œê·¸
                self.failure_log.append({
                    'filename': file_path.name,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                self.failure_count += 1
                print(f"âŒ ì‹¤íŒ¨: {file_path.name} - {e}")
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        # ì„±ê³µ ë¡œê·¸ ì €ì¥
        success_df = pd.DataFrame(self.success_log)
        success_df.to_csv(self.logs_dir / 'improved_success_log.csv', index=False, encoding='utf-8-sig')
        
        # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
        failure_df = pd.DataFrame(self.failure_log)
        failure_df.to_csv(self.logs_dir / 'improved_failure_log.csv', index=False, encoding='utf-8-sig')
        
        # ì „ì²´ ê²°ê³¼ JSON ì €ì¥
        results = {
            'summary': {
                'total_files': len(self.success_log) + len(self.failure_log),
                'success_count': self.success_count,
                'failure_count': self.failure_count,
                'success_rate': self.success_count / (self.success_count + self.failure_count) * 100 if (self.success_count + self.failure_count) > 0 else 0
            },
            'success_files': self.success_log,
            'failure_files': self.failure_log
        }
        
        with open(self.logs_dir / 'improved_conversion_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.logs_dir}")
    
    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        total = self.success_count + self.failure_count
        success_rate = (self.success_count / total * 100) if total > 0 else 0
        
        print("\n" + "="*50)
        print(" ê°œì„ ëœ ë³€í™˜ ê²°ê³¼ ìš”ì•½")
        print("="*50)
        print(f"ğŸ“„ ì´ íŒŒì¼ ìˆ˜: {total}ê°œ")
        print(f"âœ… ì„±ê³µ: {self.success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.failure_count}ê°œ")
        print(f" ì„±ê³µë¥ : {success_rate:.1f}%")
        
        if self.success_log:
            avg_length = sum(log['text_length'] for log in self.success_log) / len(self.success_log)
            print(f"ğŸ“ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {avg_length:.0f}ì")
        print("="*50)
    
    def run_conversion(self):
        """ì „ì²´ ë³€í™˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ ê°œì„ ëœ ë¬¸ì„œ ë³€í™˜ ì‹œì‘...")
        self.convert_documents()
        self.save_results()
        self.print_summary()

if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    input_path = "data/raw/base_data/extracted_files-20250722T073504Z-1-001/files"
    output_path = "data/processed/improved_processed_data"
    logs_path = "data/logs/improved_conversion_logs"
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_path, exist_ok=True)
    os.makedirs(logs_path, exist_ok=True)
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    converter = ImprovedDocumentConverter(input_path, output_path, logs_path)
    converter.run_conversion() 