import os
import json
import faiss
import numpy as np
import openai
import pandas as pd
import re
from pathlib import Path
from dotenv import load_dotenv
from rapidfuzz import fuzz, process

# âœ… í™˜ê²½ ì„¤ì •
load_dotenv()
openai.api_key = os.getenv('OPENAI_API_KEY')

# âœ… ê²½ë¡œ ì„¤ì •
CHUNKS_DIR = "output_jsonl_chunks"
VECTOR_INDEX = "vector.index"
VECTOR_METADATA = "vector_metadata.json"
DATA_LIST = "data_list.csv"

# âœ… íŒŒì¼ëª… ì •ê·œí™” í•¨ìˆ˜
def sanitize_filename(filename: str) -> str:
    name = Path(filename).stem
    name = re.sub(r'[\\/:*?"<>|()\u3000\s]+', '', name)
    return name.strip()

# âœ… ê°€ì¥ ìœ ì‚¬í•œ íŒŒì¼ëª… ì°¾ê¸°
def find_closest_filename(target, candidates):
    match = process.extractOne(target, candidates, scorer=fuzz.ratio)
    if match and match[1] > 90:
        return match[0]
    return None

# âœ… ë©”íƒ€ë°ì´í„° enrich (data_list.csv ì—°ë™)
def enrich_metadata(meta: dict, data_df: pd.DataFrame) -> dict:
    fname = meta["filename"].strip()
    row = data_df[data_df["íŒŒì¼ëª…"].str.strip() == fname]
    if not row.empty:
        row = row.iloc[0]
        for col in ["ê³µê³  ë²ˆí˜¸", "ì‚¬ì—…ëª…", "ì‚¬ì—… ê¸ˆì•¡", "ë°œì£¼ ê¸°ê´€", "ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼"]:
            meta[col] = row.get(col, "")
    return meta

# âœ… ë°ì´í„° ë¡œë“œ
index = faiss.read_index(VECTOR_INDEX)

with open(VECTOR_METADATA, "r", encoding="utf-8") as f:
    vector_metadatas = json.load(f)

data_list = pd.read_csv(DATA_LIST)

# âœ… ì²­í¬ íŒŒì¼ ë¡œë“œ (ì²­í¬ ë‹¨ìœ„ë¡œ title/subtitle/index í¬í•¨)
all_chunks = {}
loaded_files = set()
actual_files = {sanitize_filename(f): f for f in os.listdir(CHUNKS_DIR)}

for meta in vector_metadatas:
    filename = meta["filename"]
    sanitized = sanitize_filename(filename)

    if sanitized not in loaded_files:
        file_match = actual_files.get(sanitized)
        if not file_match:
            file_match = find_closest_filename(sanitized, actual_files.keys())
            if file_match:
                file_match = actual_files[file_match]
        if not file_match:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {sanitized}.jsonl")
            continue

        with open(os.path.join(CHUNKS_DIR, file_match), "r", encoding="utf-8") as f:
            all_chunks[sanitized] = [json.loads(line) for line in f]
        loaded_files.add(sanitized)

# âœ… ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰ í•¨ìˆ˜ (context window + subtitle-aware)
def search_similar_chunks(query, top_k, context_window=1):
    response = openai.embeddings.create(input=[query], model="text-embedding-3-small")
    query_embedding = np.array(response.data[0].embedding).astype("float32")

    D, I = index.search(query_embedding.reshape(1, -1), top_k)

    results = []
    seen = set()
    for idx in I[0]:
        if idx < 0 or idx >= len(vector_metadatas): continue
        meta = vector_metadatas[idx]
        meta = enrich_metadata(meta, data_list)
        filename = meta["filename"]
        sanitized = sanitize_filename(filename)
        base_idx = meta["index"]

        if sanitized not in all_chunks:
            print(f"âŒ ì²­í¬ ë¡œë”© ì‹¤íŒ¨: {sanitized}")
            continue

        chunk_list = all_chunks[sanitized]

        for offset in range(-context_window, context_window + 1):
            cidx = base_idx + offset
            if 0 <= cidx < len(chunk_list) and (sanitized, cidx) not in seen:
                seen.add((sanitized, cidx))
                chunk = chunk_list[cidx]
                results.append({
                    "text": chunk["text"],
                    "metadata": {**meta, "title": chunk["title"], "subtitle": chunk["subtitle"], "index": chunk["index"]}
                })
    return results

# âœ… GPT ë‹µë³€ ìƒì„± (title/subtitle + ë©”íƒ€ë°ì´í„° í¬í•¨)
def generate_answer(query, chunks):
    context = ""
    for c in chunks:
        m = c["metadata"]
        context += f"""
ğŸ“„ [ë¬¸ì„œ ì •ë³´]
- ì œëª©: {m.get('title', '')}
- ì†Œì œëª©: {m.get('subtitle', '')}
- ê³µê³ ë²ˆí˜¸: {m.get('ê³µê³  ë²ˆí˜¸', '')}
- ë°œì£¼ê¸°ê´€: {m.get('ë°œì£¼ ê¸°ê´€', '')}
- ì‚¬ì—…ëª…: {m.get('ì‚¬ì—…ëª…', '')}
- ì˜ˆì‚°: {m.get('ì‚¬ì—… ê¸ˆì•¡', '')}
- ë§ˆê°ì¼: {m.get('ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼', '')}

ğŸ“‘ [ë³¸ë¬¸]
{c['text']}

""".strip() + "\n\n"

    prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤.

[ì§ˆë¬¸]
{query}

[ë¬¸ì„œ]
{context}

ìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."""

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()

# âœ… ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    query = "í•œêµ­ì—°êµ¬ì¬ë‹¨ì—ì„œëŠ” ì–´ë–¤ ë‚´ìš©ì„ ë³´ëƒˆì–´?"
    results = search_similar_chunks(query, top_k=20, context_window=1)

    print(f"ğŸ” ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(results)}")
    for i, r in enumerate(results):
        m = r["metadata"]
        print(f"\nğŸ”¹ {i+1}. {m['filename']} | {m['title']} > {m['subtitle']} | idx: {m['index']}")
        print(r['text'], "...")

    print("\nğŸ§  GPT ì‘ë‹µ:")
    print(generate_answer(query, results))
